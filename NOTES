These notes were, for the most part, written before the corresponding
features were implemented.  So they're likely to be speculative and
inaccurate.

It's interesting (to me) to see the ideas become more refined.


----------------------------------
Definitions
	'form' - a syntactic part of a program
	"subr" - a built-in function
	"special form" - a function that is handled specially by eval,
			 often because its args should not be evaluated.
	"macro" - a function called from read, not from eval.
	"lexpr" - ???
	"environment - ???
    	"dynamic extent" the time a function activation is alive.

Data
	object
	  abstract superclass
	    eq?()
	boolean
	integer
	    new()
	    number?()
	    c_int()
	character
	pair (cons)
	    new()
	    consp()
	    car()
	    cdr()
	    setcar()
	    setcdr()
	symbol (atom)
	    new()
	    symbol-bound?()
	    symbol-value(sym, value, env=None)
	    set-symbol_value(sym. value, value, env=None)
	activation frame
	exception
	built-in atoms
	   #t #f lambda
	transformer
    	dynamic environment
	    continuation
	    exception handler
    	    variable bindings
    	    other?
	later...
	    string
	    vector
	    other numeric types

Program
	read-eval-print
	read
	  read-token
	string->symbol (aka intern)
	eval
	  eval-variable
	  eval-list
	print
	bind (global)
	math primitives
	string primitives

Special forms
	define
	lambda
	let

Resources

    http://srfi.schemers.org/
    http://srfi.schemers.org/srfi-18/

Layers

    storage
    storage: blocks of data, format objects.

----------------------------------

Notes

Recognizing special forms.

    It seems like there are three kinds of functions.
    Regular functions, syntaxes (syntaces?), and, um,
    special forms.

    SIOD has these.

	#define tc_subr_0 4
	#define tc_subr_1 5
	#define tc_subr_2 6
	#define tc_subr_3 7
	#define tc_lsubr  8
	#define tc_fsubr  9
	#define tc_msubr  10
	#define tc_closure 11

	tc_subr_0..3 is a regular function of 0..3 arguments.
	tc_lsubrs are... gc-status
	tc_fsubrs are... define lambda set! quote the-environment
	tc_msubrs are... if begin and or let-internal
	tc_closures are created at runtime.

    I'm certain I don't see the difference yet.

Section 5.2, para 3.

    "Variable definitions appearing within the body of such an
    expression, or within the bodies of a library or top-level
    program, are treated as a set of letrec* bindings"

    "such an expression" refers to expressions that declare local
    variables, e.g., lambda, let, and friends.  So a variable
    created by a definition is just another local variable.
    And a definition can appear anywhere.

Symbol Table Layout.

    Top level and each library have their own environment.  (Q.  Does
    a library's env start empty?  Can't be quite empty...)  Binding
    expressions push a scope onto the current environment.  Definitions
    create an entry in the current scope.

    The absolute simplest implementation would have the env as a list
    of scopes, and each scope is a list of (name . value) pairs.

    def lookup(name):
	for scope in env:
	    for var, value in scope:
	       if var == name:
		    return value

    But...  name is a symbol.  Each symbol is a unique object.  Can
    we turn it inside out where we start from the symbol and find the
    current binding?  In constant time, even?  Need to be
    thread-safe...

    In SIOD, define takes an optional env.  If env is null, then
    define just writes the symbol's value cell.  If env is non-null,
    then define does this.

        (set! env (cons (cons var (car env)) (cons val (cdr env))))

    So env has two parallel lists.  A list of vars (symbols) and
    a list of values.  At environment exit time, those would just
    be peeled back.

    That's cool.  Symbol lookup is constant time.  Symbol definition
    is constant time.  Scope entry is constant time.  Scope exit
    is O(number of name conflicts), which is normally small.

    The env is part of the reader's state, so the reader has
    to have per-thread (probably automatic) state.

Section 5.10 says that some storage is immutable.  Figure out how to do that...

----------------------------------
9/24/2008

Extensions
define new in-memory object formats.
define new scheme data types.
define new scheme functions.
define new scheme syntax.

A scheme function has:
   a namespace (library),
   a name,
   an arg list,
   code.

A scheme syntax has:
   a namespace (library),
   a name,
   an arg list,
   code.

A namespace is a Scheme <library name> form, as a C string.
E.g., "(rnrs base (6))".

Imagine two include files:
   scheme-extension.h - used to extend the Scheme core
   scheme.h - used to embed Scheme.

So,something like this.
#include "extend.h"

DEFINE_PROC("boolean?", (x))
{
   return make_boolean(is_boolean(x));
}

DEFINE_SYNTAX("set!", (name value))
{
    
}

DEFINE_LIBRARY_PROC("foo", (mylib sublib (1 2 3)))
{
    return make_boolean(false);
}

----------------------------------
9/28/2008

primitives have the following macros.
    ARGLIST
    ENV
primitives have the following control-flow macros.
    RETURN(value);
    YIELD(value);    /* only used for multi-value functions */
    RAISE(condition);
    RAISE_CONTINUABLE(condition);
The last three leave all local variables in an undefined state.
(Where's a good place to save them?)
    EVAL(object);
    SAVE(variable);  /* var must be type (obj_t *) */
    RESTORE(variable);

Implement the stack as a list?

----------------------------------
9/28/2008

labels in SICP section 5.4:
     eval-dispatch
     ev-self-eval
     ev-variable
     ev-quoted
     ev-lambda
     ev-application
*    ev-appl-did-operator
     ev-appl-operand-loop
*    ev-appl-accumulate-arg
     ev-appl-last-arg
*    ev-appl-accum-last-arg
     apply-dispatch
     primitive-apply
     compound-apply
     ev-begin
     ev-sequence
*    ev-sequence-continue
     ev-sequence-last-expr
     ev-if
*    ev-if-decide
     ev-if-alternative
     ev-if-consequent
     ev-assignment
*    ev-assignment-1
     ev-definition
*    ev-definition-1
     read-eval-print-loop
*    print-result
     unknown-expression-type
     unknown-procedure-type
     signal-error

* used as return address.

----------------------------------

eval calls
    eval_list

eval_list calls
    eval_list
    eval_arglist
    eval_procedure

eval_arglist calls
    eval_arglist
    eval

eval_procedure calls
    primitives
    eval_apply

eval_apply calls
    eval_multi

eval_multi calls
    eval

primitives call
    eval

----------------------------------
10/01/2008

eval simple object:
    build one frame: { cont=0, exp,env=..., val=0 }
    call b_eval.
    b_eval sets val=..., calls RETURN.

eval nilary procedure:
    build one frame: { cont=0, exp,env=..., val=0 }
    call b_eval.
    b_eval pushes 2nd frame: { cont=b_have_operator, exp=... } -> { cont=0, exp,env=..., val=0}
    call b_eval. <====???
    b_eval sets val=#<proc '='>, calls RETURN.
    call b_have_operator.


----------------------------------
10/17/2008

Read barriers.

I think each obj_* operation can verify its subject on entry with
something like this.

	ENSURE_TOSPACE(obj);

#define ENSURE_TOSPACE(x) (!is_null((x)) && ((x) < to_space || (x) >= to_space_end) ? (x) = move_obj(x) : (x))

Or, as a function,

    obj_t *ensure_tospace(obj_t *obj)
    {
	if (is_null(obj))
	    return obj;
	if (to_space <= obj && obj < to_space_end)
	    return obj;
	return move_obj(obj);
    }
    #define ENSURE_TOSPACE(x) ((x) = ensure_tospace(x))

Anyway, everytime an obj's public method dereferences a pointer field,
it also does the ensure_tospace thing.

    obj_t *some_obj_get_thingie(obj_t *obj)
    {
	ENSURE_TOSPACE(obj);
        some_obj_t *so = (some_obj_t *)obj;
        return ensure_tospace(so->so_thingie);
    }

----------------------------------
The alternative is to keep auto storage locations on a linked list
or stack, and traverse that list when flipping.

    struct obj_ref {
        obj_t **ref;
	obj_ref *next;
    };

    __thread obj_ref *auto_head;

    #define OBJ(x) obj_t *x; obj_ref r = { &x, auto_head }; auto_head = r;
       
and make it illegal to DECLARE an obj in a loop.

    my_proc()
    {
	OBJ(o);
	for (o = some_list; o; o = pair_cdr(o))
	    ...;
    }

But how do we find implicit pops?  Compare stack pointer?
Zap the list each time through the threaded eval loop?

----------------------------------
That doesn't quite cut it.  Instead, let's have a new arg that gets
passed to every function.  Call it HEAP or ROOT or ALLOC or something.

Each function or block entry has code to initialize HEAP:

    my_proc(HEAP__, ...)                     | This much comes
    {                                        | from the DEFINE_PROC
        some_struct HEAP = { HEAP__, ... };  | macro.
	...
	return make_pair(HEAP, some_car, some_cdr);
    }

    #define THIS_FUNCTION_USES_THE_HEAP some_struct HEAP = { HEAP__, ... }

Then roots are defined from HEAP.

        HEAP_ROOT(obj); obj = make_symbol(L"foo");

    #define HEAP_ROOT(obj) obj_t *obj = NIL;  heap_record_obj(HEAP, obj);

----------------------------------
Third alternative.  May be independent of the first two.

Make FRAME a thread-global variable.
Then blocks just return a value.
Each thread's FRAME is a root.

----------------------------------
11/28/2008

I'm up against the problem that a lot of primitives need to be
implemented.  Some of them seem to be best implemented as macros.
E.g., let in terms of lambda and letrec (from r6rs Appendix B).

    (define-syntax let
      (syntax-rules ()
        ((let ((name val) ...) body1 body2 ...)
         ((lambda (name ...) body1 body2 ...)
          val ...))
        ((let tag ((name val) ...) body1 body2 ...)
         ((letrec ((tag (lambda (name ...)
                          body1 body2 ...)))
            tag)
          val ...))))

Note that only "named let" uses letrec, so you can define let in terms
of letrec and letrec in terms of let.

From the Scheme FAQ:

    (define-syntax letrec
	(syntax-rules ()
	  ((_ ((var init) ...) . body)
           (let ()
             (define var init)
	     ...
	     (let () . body)

But many primitives can be implemented as simple procedures.  They
don't need macros.

Trivial example: list.

	(define (list . args) args)
	; update 5/9/2009 - this is wrong.
	; `list' returns a newly allocated list. (ref. r6rs 11.9)

So I'm thinking I should start on a system of loading libraries from
source files at startup.  That means defining a search path and a way
to control loading.  Or maybe the C code should just have a read-file
primitive and a mechanism for reading a file into a namespace.  Then
I could implement the import mechanism in Scheme.

----------------------------------
12/2/2008

Finishing the reader.

Things the scanner can return:
       begin-datum-comment: #;
       identifier (symbol)
       booleans: #t, #f       
       character
       string	
       number (fixnum w/ sign)
       ( ) [ ] .
       begin-vector: #(
       begin-bytevector: #vu8(
       quote: '
       quasiquote: `
       unquote: ,	   
       unquote-splicing: ,@
       syntax: #'
       quasisyntax: #`
       unsyntax: #,
       unsyntax-splicing: #,@

Things not to implement yet: many character formats,
non-decimal-fixnum numbers, vectors, bytevectors.

Grammar:

    program ::= datum*

    datum ::= lexeme | compound

    lexeme ::= boolean | character | string | number

    compound ::= ( datum* ) | [ datum* ] | abbrev datum
		 (or vector or bytevector)

How to handle comment?
    comment ::= ... | #; interlexeme-space datum

Have a datum-sequence nonterminal which is made of data and
datum-comments.  The actions discard the commented data.  Or have a
parallel set of productions for commented data which don't build
anything.  (I like the latter...)

----------------------------------
4/13/2009

Libraries.

It would be good to write the libraries (import statement processing,
search path, etc.) in Scheme.  But we need to read a lot of code to
bootstrap.

There could be two import mechanisms, a simplified bootstrap method
and the full-boat method.  I rejected that dichotomy for read, though.

What does the import mechanism do?  Each library has a C file and a
Scheme file with the same basename (foo.c and foo.scm).  The C file
has a namespace declaration, something like this.

    DEFINE_LIBRARY(L"(rnrs foo (6))");

Then it has the usual function definitions.

The Scheme file is wrapped in a (library ...) declaration.

    (library (rnrs foo (6))
      (export foo-fcn)
      (import (rnrs base)
              (rnrs xyzzy))
      (define (foo-fcn) ...)
    )

Sometime during program initialization, we iterate through the
declared libraries and try to load this file.

    '%s/lib/%s.scm' % (dir_name(executable), lib_name)

To load a file, use fopen() and make_file_instream(), then loop in
read_stream().  Should fail gracefully.

So the library special form has to be a built-in.

There's some recursive magic where if foo imports bar, and bar imports
baz, then baz has to be loaded first.  We should also duplicate
Python's import once mechanism.

Or, we "just" implement the I/O library (subset) which I think
would include:
    (get-datum)
    (standard-input-port)

pseudo-code main program.

    load_std_libraries()
    exec = argv.pop()
    if argv:
	load_file(argv[0], null_env)
    else:
	read_loop(stdin, r6rs_lib())

----------------------------------
5/2/2009

Libraries again.

Here's the R6RS example.

    (library (hello)
      (export hello-world)
      (import (rnrs base)
              (rnrs io simple))
      (define (hello-world)
        (display "Hello World")
        (newline)))

Here are the primitives for environments.

    (eval <expr> <env>)
    (environment <import-spec>)
    (library
      (export <export-spec> ...)
      (import <import-spec> ...)
      <library body>)

I think each C source file should have a LIBRARY declaration like
this.  LIBRARY(L"(rnrs base (6))") That defines a static variable,
the current library.  I can't think of a reason why C sources would
have dependencies.

Each library may also have a Scheme source file which appends to the C
definitions.  It's probably an error to have two Scheme files define
the same library, but it's expected to have both Scheme and C files
for the same library.

----------------------------------
5/4/2009

Need to partition the lib module into two pieces.  One implements the
correct semantics of libraries.  The other reads files and parses
(library ...) forms.

Library semantics mean that each library has a namespace (an env)
and symbols imported into it are bound immutably.  A library has
an import list and an export list, both with rebindings.

----------------------------------
5/9/2009

What about anonymous libraries?  Reachable from C but not from Scheme.
Useful?  I may be trying too hard to avoid polluting Scheme's
namespaces.

----------------------------------
6/25/2009

Aboard Carnival Spirit.
Macro expansion is complex.  There are some other expansion things
that I'm not doing, such as splicing begin and let.  To handle
all those things, I'd like to be using Scheme.  The problem is that
I don't know what the best subset to implement is.  Ideally, there
would be a C core which is just enough to implement the full language.

Maybe I should relax the rules, implement the let family and anything
else that seems useful, and get on with it.  Then when I've written
syntax-rules using full Scheme, I can go back and figure out what it
could do without and reimplement some bits in Scheme.

And I still don't quite understand why multiple expansion levels
are necessary.  R6RS Section 7.2 tries to explain it.

I'm getting the feeling that Scheme is just circular, that Scheme
is the only language for implementing Scheme.

I have a feeling that the next thing to implement is syntax objects,
and that they will be a primitive type.

Does the standard provide a way to extend the numerical tower?

Reading list: 1.4-1.10, 3, 7.2, 9, 10.

Some previously unstated goals:

    Follow the standard whenever possible -- don't improvise.

    Non-heap memory use is constant.  No malloc() and no unbounded
    recursion in C.

    It should be possible to build the interpreter with good old
    "./configure && make && make install".

----------------------------------
~7/1/2009 - 8/19/2009

I upgraded my workstation from Ubuntu 8.04 to 9.04.  When I finished,
libunicode was gone.  Removed from the repository!  I turns out
that libunicode has been deprecated for several years, and it was a
poor choice to use it.  So I've been unable to compile Scheme for
a while now.

So I've been researching Unicode libraries, and also learning more
about Unicode itself.  It's HUGE!  We humans have had thousands of
years to design writing systems, and up until about 1980, there was no
thought about making them easy for computers to work with.  So
right now I'm reading the Unicode spec and R6RS very carefully to
understand what I actually need.

I'm thinking about implementing my own Unicode library, derived
directly from the published UnicodeData.txt and related files.

There are lots of terms, and I don't know exactly what they mean yet.

  - Character

  - Code Point
        U+0000 through U+10FFFF.

  - Glyph

  - Property

  - Category(?)
        aka the General_Category property

  - "Unicode scalar value" (from R6RS 11.11)  Same as a code point?
        R6RS says that a scalar value is a code point outside the
	surrogate range (U+D800 .. U+DFFF).

Then there are encoding and decoding.  But I'm still planning to use
glibc for that (for now).  Internally, it's all UTF-32.

Unicode defines four normalization forms.  R6RS has four procedures
that do normalization: string-normalize-nfd, string-normalize-nfkd,
string-normalize-nfc, and string-normalize-nfkc.

Normalization Forms D and KD decompose characters.  A-umlaut becomes
A followed by Umlaut.

Normalization Forms C and KC compose characters.

Normalization Forms KC and KD are compatibility forms.  I don't know
what that means.  Unicode, section 5.3:

    "Compatibility.  The decomposition may remove some information
    (typically formatting information) that is important to preserve
    in particular contexts.)"

I still don't know what that means.  From the Python documentation
(module unicodedata):

    In addition to these two forms, there are two additional normal
    forms based on compatibility equivalence. In Unicode, certain
    characters are supported which normally would be unified with
    other characters. For example, U+2160 (ROMAN NUMERAL ONE) is
    really the same thing as U+0049 (LATIN CAPITAL LETTER I). However,
    it is supported in Unicode for compatibility with existing
    character sets (e.g. gb2312).

I think the only features Scheme needs are:

    general category
    comparison
    case-independent comparison
    char-upcase (simple uppercase mapping)
    char-downcase (simple lowercase mapping)
    char-titlecase (simple titlecase mapping)
    tolower
    toupper
    totitle
    case folding (both simple and complex).
    normalization

Python's str type and unicodedata module implement all of those.

R6RS-lib claims that all the properties are available from these files.

    UnicodeData.txt
    SpecialCasing.txt
    WordBreakProperty.txt
    CaseFolding.txt

We need...

    general category: UnicodeData.txt column 2 (zero-based)

    comparison: compare code point values

    case-independent comparison: case-fold then compare code point values

    char-upcase: UnicodeData.txt column 12

    char-downcase: UnicodeData.txt column 13

    char-titlecase: UnicodeData.txt column 14

    char-foldcase: if not Turkic I,
		       if CaseFolding.txt column 1 in {C, S},
		           CaseFolding.txt column 2

    char-alphabetic?: Alphabetic property from DerivedCoreProperties.txt

    char-numeric?: 

    char-whitespace?: White_Space property from PropList.txt

    char-upper-case?: Uppercase property from DerivedCoreProperties.txt

    char-lower-case?: Lowercase property from DerivedCoreProperties.txt

    char-title-case?: general category == Lt

    string-upcase: SpecialCasing.txt column 3 or UnicodeData.txt column 12

    string-downcase: SpecialCasing.txt column 1 or UnicodeData.txt column 13

    string-titlecase: SpecialCasing.txt column 2 or UnicodeData.txt column 14

    string-foldcase: if CaseFolding.txt column 1 in {C, F},
		         CaseFolding.txt column 2

    normalization: See http://www.unicode.org/reports/tr15/Normalizer.java

Update 8/25
    The bytecode chapter specified encoding/decoding of utf-8, utf-16,
    and utf32.  And the I/O ports chapter has a whole section on
    transcoding.

----------------------------------
8/21/2009

The above summarizes what we need.  Let's do the simplest possible
thing.  A table with 0x110000 entries in it, and each entry looks
like this.

    typedef enum unicode_type_bit {
    	ut_alphabetic = 1 << 0,
    	ut_numeric    = 1 << 1,
    	ut_whitespace = 1 << 2,
    	ut_upper_case = 1 << 3,
    	ut_lower_case = 1 << 4,
    	ut_title_case = 1 << 5,
    } unicode_type_bit_t;

    typedef struct unicode_data {
    	enum general_category_t  ud_general_category;
    	bool 			 ut_alphabetic:1,
    	bool 			 ut_numeric:1,
    	bool 			 ut_whitespace:1,
    	bool 			 ut_upper_case:1,
    	bool 			 ut_lower_case:1,
    	bool 			 ut_title_case:1,
	wchar_t 		 ud_simple_upcase;
	wchar_t 		 ud_simple_downcase;
	wchar_t 		 ud_simple_titlecase;
	wchar_t 		 ud_simple_foldcase;
	wchar_t 	       	*ud_full_upcase;
	wchar_t 	        *ud_full_downcase;
	wchar_t 		*ud_full_titlecase;
	wchar_t 		*ud_full_foldcase;
    } unicode_data_t;

That wastes a ton of space but it's the simplest thing.  Write a
Python script to generate the table; the runtime functions are
obvious.

----------------------------------
8/23/2009

The Unicode problem is resolved for now.  I didn't implement the full
solution outlined above, but I have the minimal subset to remove
dependencies from libunicode.  So Scheme builds again.  w00t.

And the framework is there to implement the rest of the Unicode
dependencies.

But let's get back to macros.

A while ago, I created an experimental special form called mu.  mu is
the successor to lambda.  The Scheme spec calls for some rewriting as
a lambda form is evaluated, which my lambda evaluator doesn't do.

mu, however, passes the incoming form to a Scheme procedure to
transform it, then creates a procedure from the transformed form.

I just now implemented "let" through mu.  Observe.

    ~/scheme> ./scheme
    > (define f (mu () (let ((v0 i0) (v1 i1)) (+ v0 v1))))
    > (define i0 3)
    > (define i1 4)
    > (f)
    7
    > (procedure? f)
    #t
    > f
    (lambda () ((lambda (v0 v1) (+ v0 v1)) i0 i1))
    > 

So that's a start.

----------------------------------
9/2/2009

I'm feeling the need to rewrite the evaluator.  This is partly
from reading the book, "Scheme 9 from Empty Space".

http://www.t3x.org/nmh/book-pdfs/scheme-9-from-empty-space.zip

It's not so much a book as a very well commented source code
listing.  But it uses a somewhat different interpreter model
than I have.  The primitives are more "C-like" than my weird
macro soup.

Current interpreter strengths:
	works. (-:
	is continuation based.  call/cc works.
	should allow exceptions to work without modifying the core.

Current interpreter weaknesses:
	roots are fragile and slow.
	dynamic-wind unimplemented
	multiple values unimplemented
	API too complex for primitive procs, too simple for primitive syntax.
	hard to call Scheme from C
	warps my brain
	no checking C procs for right number of args
	crashes on any error.

----------------------------------
9/5/2009

Here are the forms declared (non-library) syntax in r5rs.

	<variable>

	(quote <datum>)
	'<datum>
	<constant>

	(<operator> <operand1> ...)

	(lambda <formals> <body>)

	(if <test> <consequent> <alternate>)
	(if <test> <consequent>)

	(set! <variable> <expression>)

	(quasiquote <qq template>)
	`<qq template>

<variable>, <constant>, and (<operator> <operand1> ...) are not keywords.
The keywords are quote, lambda, if, set!, and quasiquote.  Notably missing
are define-syntax
